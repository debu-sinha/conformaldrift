{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Hallucination Detection with Conformal Prediction\n",
        "\n",
        "This notebook shows how to build a hallucination detector for RAG systems using conformal prediction, then stress-test it under distribution shift.\n",
        "\n",
        "**What you'll learn:**\n",
        "- Build a conformal predictor for RAG hallucination detection\n",
        "- Calibrate it on your documents\n",
        "- Test what happens when users ask about new topics\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/debu-sinha/conformaldrift/blob/main/examples/01_rag_hallucination_detection.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install conformal-drift langchain langchain-openai langchain-community chromadb sentence-transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = 'your-key-here'  # Replace with your key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Build a Simple RAG System\n",
        "\n",
        "We'll create a RAG system with some technical documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Sample knowledge base - Python documentation\n",
        "knowledge_base = [\n",
        "    \"Python lists are ordered, mutable sequences. You can add items with append() or extend().\",\n",
        "    \"Python dictionaries store key-value pairs. Keys must be hashable. Access values with dict[key].\",\n",
        "    \"List comprehensions provide a concise way to create lists: [x**2 for x in range(10)].\",\n",
        "    \"The with statement ensures proper resource management. Files opened with 'with' are automatically closed.\",\n",
        "    \"Decorators modify function behavior. Use @decorator syntax above the function definition.\",\n",
        "    \"Python's GIL (Global Interpreter Lock) allows only one thread to execute Python bytecode at a time.\",\n",
        "    \"Virtual environments isolate project dependencies. Create with: python -m venv myenv\",\n",
        "    \"Type hints improve code readability: def greet(name: str) -> str: return f'Hello {name}'\",\n",
        "    \"Generators yield values lazily, saving memory for large datasets. Use yield instead of return.\",\n",
        "    \"Context managers implement __enter__ and __exit__ methods for resource management.\",\n",
        "]\n",
        "\n",
        "# Create vector store\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_texts(knowledge_base, embeddings)\n",
        "\n",
        "# Create RAG chain\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"Answer the question based ONLY on the following context. \n",
        "If you cannot answer from the context, say \"I don't have information about that.\"\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "print(\"RAG system ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Define Hallucination Score (Nonconformity Score)\n",
        "\n",
        "The key insight: **responses that don't align with retrieved documents are likely hallucinations**.\n",
        "\n",
        "We use embedding similarity as our score:\n",
        "- **Low score** (high similarity): Response grounded in documents\n",
        "- **High score** (low similarity): Potential hallucination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Use a fast, accurate embedding model\n",
        "scorer = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def compute_hallucination_score(response: str, source_docs: list) -> float:\n",
        "    \"\"\"\n",
        "    Compute how likely the response is a hallucination.\n",
        "    \n",
        "    Returns:\n",
        "        Score between 0 and 1. Higher = more likely hallucination.\n",
        "    \"\"\"\n",
        "    if not source_docs:\n",
        "        return 1.0  # No sources = definitely suspicious\n",
        "    \n",
        "    # Get embeddings\n",
        "    response_emb = scorer.encode([response])\n",
        "    doc_texts = [doc.page_content for doc in source_docs]\n",
        "    doc_embs = scorer.encode(doc_texts)\n",
        "    \n",
        "    # Compute max similarity to any source document\n",
        "    similarities = cosine_similarity(response_emb, doc_embs)[0]\n",
        "    max_similarity = max(similarities)\n",
        "    \n",
        "    # Nonconformity = 1 - similarity\n",
        "    return 1 - max_similarity\n",
        "\n",
        "# Test it\n",
        "result = rag_chain({\"query\": \"How do I create a list in Python?\"})\n",
        "score = compute_hallucination_score(result['result'], result['source_documents'])\n",
        "print(f\"Question: How do I create a list in Python?\")\n",
        "print(f\"Response: {result['result'][:100]}...\")\n",
        "print(f\"Hallucination score: {score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Calibrate the Hallucination Detector\n",
        "\n",
        "Run questions we know are answerable from our knowledge base to establish baseline scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calibration questions - things we KNOW are in our knowledge base\n",
        "calibration_questions = [\n",
        "    \"What are Python lists?\",\n",
        "    \"How do dictionaries work in Python?\",\n",
        "    \"What is a list comprehension?\",\n",
        "    \"How does the with statement work?\",\n",
        "    \"What are decorators in Python?\",\n",
        "    \"What is the GIL?\",\n",
        "    \"How do I create a virtual environment?\",\n",
        "    \"What are type hints?\",\n",
        "    \"How do generators work?\",\n",
        "    \"What are context managers?\",\n",
        "    \"How do I add items to a list?\",\n",
        "    \"What makes dictionary keys valid?\",\n",
        "    \"Why use the with statement for files?\",\n",
        "    \"How do I use the @ syntax?\",\n",
        "    \"What does yield do?\",\n",
        "]\n",
        "\n",
        "print(\"Calibrating hallucination detector...\")\n",
        "calibration_scores = []\n",
        "\n",
        "for q in calibration_questions:\n",
        "    result = rag_chain({\"query\": q})\n",
        "    score = compute_hallucination_score(result['result'], result['source_documents'])\n",
        "    calibration_scores.append(score)\n",
        "    print(f\"  {q[:40]:40} -> score: {score:.3f}\")\n",
        "\n",
        "calibration_scores = np.array(calibration_scores)\n",
        "print(f\"\\nCalibration complete!\")\n",
        "print(f\"Mean score: {calibration_scores.mean():.3f}\")\n",
        "print(f\"Std score: {calibration_scores.std():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Set Up Conformal Prediction Threshold\n",
        "\n",
        "Using conformal prediction, we find a threshold that flags hallucinations while maintaining 90% coverage on grounded responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from conformal_drift import ConformalDriftAuditor\n",
        "\n",
        "# Initialize auditor with calibration scores\n",
        "# alpha=0.1 means we want 90% coverage (10% false positive rate)\n",
        "auditor = ConformalDriftAuditor(\n",
        "    calibration_scores=calibration_scores,\n",
        "    alpha=0.1\n",
        ")\n",
        "\n",
        "# The threshold is the 90th percentile of calibration scores\n",
        "threshold = np.percentile(calibration_scores, 90)\n",
        "print(f\"Hallucination threshold: {threshold:.3f}\")\n",
        "print(f\"Responses with score > {threshold:.3f} will be flagged as potential hallucinations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Test on Out-of-Domain Questions (Distribution Shift!)\n",
        "\n",
        "Now let's see what happens when users ask about topics NOT in our knowledge base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Questions about topics NOT in our knowledge base\n",
        "out_of_domain_questions = [\n",
        "    \"How does asyncio work in Python?\",  # Not in KB\n",
        "    \"What is FastAPI?\",  # Not in KB\n",
        "    \"How do I use pandas DataFrames?\",  # Not in KB\n",
        "    \"Explain Python's memory management\",  # Not in KB\n",
        "    \"What is the difference between Python 2 and 3?\",  # Not in KB\n",
        "    \"How do I deploy a Flask app?\",  # Not in KB\n",
        "    \"What are dataclasses?\",  # Not in KB\n",
        "    \"How does multiprocessing work?\",  # Not in KB\n",
        "]\n",
        "\n",
        "print(\"Testing on out-of-domain questions...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "ood_scores = []\n",
        "for q in out_of_domain_questions:\n",
        "    result = rag_chain({\"query\": q})\n",
        "    score = compute_hallucination_score(result['result'], result['source_documents'])\n",
        "    ood_scores.append(score)\n",
        "    \n",
        "    flagged = \"FLAGGED\" if score > threshold else \"OK\"\n",
        "    print(f\"Q: {q}\")\n",
        "    print(f\"A: {result['result'][:80]}...\")\n",
        "    print(f\"Score: {score:.3f} [{flagged}]\")\n",
        "    print()\n",
        "\n",
        "ood_scores = np.array(ood_scores)\n",
        "print(f\"\\nOut-of-domain: {sum(s > threshold for s in ood_scores)}/{len(ood_scores)} flagged\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Audit Coverage Under Distribution Shift\n",
        "\n",
        "The key question: **Does our 90% coverage guarantee hold when the question distribution shifts?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mix in-domain and out-of-domain questions at different ratios\n",
        "in_domain_questions = calibration_questions.copy()\n",
        "\n",
        "def create_shifted_test_set(shift_intensity: float, n_samples: int = 20):\n",
        "    \"\"\"\n",
        "    Create a test set with specified ratio of out-of-domain questions.\n",
        "    shift_intensity = 0.0 means all in-domain\n",
        "    shift_intensity = 1.0 means all out-of-domain\n",
        "    \"\"\"\n",
        "    n_ood = int(n_samples * shift_intensity)\n",
        "    n_id = n_samples - n_ood\n",
        "    \n",
        "    # Sample questions\n",
        "    np.random.seed(42)\n",
        "    id_qs = list(np.random.choice(in_domain_questions, min(n_id, len(in_domain_questions)), replace=True))\n",
        "    ood_qs = list(np.random.choice(out_of_domain_questions, min(n_ood, len(out_of_domain_questions)), replace=True))\n",
        "    \n",
        "    questions = id_qs + ood_qs\n",
        "    labels = [True] * len(id_qs) + [False] * len(ood_qs)  # True = grounded, False = should be flagged\n",
        "    \n",
        "    return questions, labels\n",
        "\n",
        "# Test at different shift intensities\n",
        "shift_levels = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "results = []\n",
        "\n",
        "print(\"Auditing coverage under distribution shift...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for shift in shift_levels:\n",
        "    questions, labels = create_shifted_test_set(shift)\n",
        "    \n",
        "    # Compute scores\n",
        "    scores = []\n",
        "    for q in questions:\n",
        "        result = rag_chain({\"query\": q})\n",
        "        score = compute_hallucination_score(result['result'], result['source_documents'])\n",
        "        scores.append(score)\n",
        "    \n",
        "    # Coverage = fraction of grounded responses correctly not flagged\n",
        "    grounded_mask = np.array(labels)\n",
        "    grounded_scores = np.array(scores)[grounded_mask]\n",
        "    \n",
        "    if len(grounded_scores) > 0:\n",
        "        coverage = np.mean(grounded_scores <= threshold)\n",
        "    else:\n",
        "        coverage = np.nan\n",
        "    \n",
        "    results.append({\n",
        "        'shift': shift,\n",
        "        'coverage': coverage,\n",
        "        'n_grounded': sum(labels),\n",
        "        'n_halluc': len(labels) - sum(labels)\n",
        "    })\n",
        "    \n",
        "    print(f\"Shift {shift:.0%}: Coverage = {coverage:.1%} (on {sum(labels)} grounded responses)\")\n",
        "\n",
        "print(\"\\nNominal coverage target: 90%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Visualize Coverage Degradation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "shifts = [r['shift'] for r in results]\n",
        "coverages = [r['coverage'] for r in results]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "ax.plot(shifts, coverages, 'b-o', linewidth=2, markersize=10)\n",
        "ax.axhline(y=0.9, color='r', linestyle='--', linewidth=2, label='90% Target')\n",
        "ax.fill_between([0, 1], [0.85, 0.85], [0.95, 0.95], alpha=0.2, color='green', label='Â±5% Tolerance')\n",
        "\n",
        "ax.set_xlabel('Out-of-Domain Question Ratio', fontsize=12)\n",
        "ax.set_ylabel('Coverage on Grounded Responses', fontsize=12)\n",
        "ax.set_title('RAG Hallucination Detector Coverage Under Topic Shift', fontsize=14)\n",
        "ax.set_xlim(-0.05, 1.05)\n",
        "ax.set_ylim(0, 1.05)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Add annotations\n",
        "for s, c in zip(shifts, coverages):\n",
        "    if not np.isnan(c):\n",
        "        ax.annotate(f'{c:.0%}', (s, c), textcoords=\"offset points\", xytext=(0, 10), ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('rag_coverage_shift.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Conformal prediction gives coverage guarantees** - but only for in-distribution data\n",
        "\n",
        "2. **Topic shift breaks guarantees** - when users ask about topics not in your knowledge base, the detector may behave unpredictably\n",
        "\n",
        "3. **Test before you deploy** - use this audit to understand how your guardrail degrades under realistic shift scenarios\n",
        "\n",
        "4. **Monitor in production** - track the distribution of hallucination scores to detect shift early\n",
        "\n",
        "## What to do when coverage drops:\n",
        "- Expand your knowledge base to cover new topics\n",
        "- Recalibrate the detector periodically with new data\n",
        "- Set more conservative thresholds for high-stakes applications"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
